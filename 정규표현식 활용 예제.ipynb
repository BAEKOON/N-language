{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1.어간화를 수행하는 함수를 정의하고, 텍스트에 적용하여 결과를 비교하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word) :\n",
    "    regexp = r'^(.*?)(ing|ed|ous|ious|ment|ive|ies|es|s|ment|ful|ly|ness)?$'\n",
    "    #r''~raw string :백슬래시 없는데 굳이? 있으나 마나임 - 코딩 테스트 해보기\n",
    "    #(.*?) 묶음()으로 시작하고(^) (접미사)들 묶음으로 끝나는 단어($)중 접미사가 있거나 없거나(?)\n",
    "    #.이 0번 이상 반복(*) * 적용하거나 안 하거나(?) -> 공백문자 제외 모든 단어\n",
    "    stem, suffix = re.findall(regexp,word)[0] #[1]로 바꾸면 list out of range\n",
    "    #findall(regexp의 pattern을 따르는,word를) 리스트값으로 리턴\n",
    "    #2번 문제로 보아 [(stem,suffix)] 형태로 들어감 -> 0으로 꺼내서 각 주소값 참조시킴\n",
    "    return stem\n",
    "    #stem만 필요하니까 stem 만 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"BENGALURU: At least 10 new AI-based jobs are being created for every 100 positions made redundant \n",
    "in traditional technology, experts in the field have said. However, the new roles are not being created \n",
    "as quickly as the positions that are eliminated and companies are increasingly training talent \n",
    "to fill the gap in artificial intelligence skills.\n",
    "\"\"\"\n",
    "#출처\n",
    "#economics times article\n",
    "#Only 10 jobs created for every 100 jobs taken away by Artificial Intelligencev By Ayan Pramanik, Oct 01, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ljy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt') #~'문장 분리기'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "#punkt 안 하니까 에러, 위 쪽 코드 실행하여 설치 필요(한 번만 설치하고 이후에는 중복 설치되지 않게 주석 처리해주시면 됩니다.ㄷ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENGALURU', ':', 'At', 'least', '10', 'new', 'AI-bas', 'job', 'are', 'be', 'creat', 'for', 'every', '100', 'position', 'made', 'redundant', 'in', 'traditional', 'technology', ',', 'expert', 'in', 'the', 'field', 'have', 'said', '.', 'However', ',', 'the', 'new', 'rol', 'are', 'not', 'be', 'creat', 'a', 'quick', 'a', 'the', 'position', 'that', 'are', 'eliminat', 'and', 'compan', 'are', 'increasing', 'train', 'talent', 'to', 'fill', 'the', 'gap', 'in', 'artificial', 'intelligence', 'skill', '.']\n"
     ]
    }
   ],
   "source": [
    "print([stem(t) for t in tokens])\n",
    "#created -> creat / experts -> expert / roles -> rol 등으로 tokenize 된 것 확인 가능\n",
    "#regexp에 접미사 추가한 거 적용됐는지 혹은 기사에 적용할만한 접미사 없는지 확인하고 추가,적용해서 보고서 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2.다음의 정규표현을 사용하여 어간화를 적용하고 결과를 비교하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$','processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processe', 's')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$','processes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <결과 비교>\n",
    "#### (.*?) 적용시 process 와 es 로 나뉨\n",
    "#### (.*) 적용 시 processe 와 s 로 나뉨\n",
    "#### 이유 : .* 적용 시 어간 부분이 더 길어지도록 match 된다고 함 // (.*?) 적용 시 (.*) 보다 어간이 짧은 형태로 match 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 3. 한국어에 어간화를 적용하는 방법에 대해 생각해보고, 한국어 텍스트에 적용하여 결과를 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기사 보고 suffix 목록화, 언어학 강의자료 연계 내용 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix: 을,를,의,와,과,은,는,에,하여,거나,이,가,나,고,다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def koreanstem(word) :\n",
    "    regexp = r'^(.*?)(을|를|의|와|과|은|는|에|하여|거나|이|가|나|고|다|로|인|으로)?$'\n",
    "    stem, suffix = re.findall(regexp,word)[0]\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "korraw = '''제18호 태풍 '미탁'이 당초 예상보다 일찍 한반도에 상륙할 것으로 보입니다.\n",
    "기상청에 따르면 '미탁'은 2일 정오 현재 제주도 서귀포 서남서쪽 약 230㎞ 해상에서 시속 30㎞로 북북동쪽으로 이동 중입니다.\n",
    "중간 강도의 중형급 태풍인 '미탁'의 중심기압은 985hPa(헥토파스칼), 중심 부근 최대 풍속은 초속 27ｍ(시속 97㎞)다. \n",
    "초속 15ｍ 이상 강풍이 부는 반경은 300㎞입니다. 당초 '미탁'은 이날 밤 12시쯤 전남 해안에 상륙할 것으로 예보됐지만, \n",
    "이동 속도가 빨라지면서 이날 오후 9∼10시께 전남 해안에 상륙할 것으로 예보가 보완됐습니다. 윤기한 기상청 통보관은 \"오늘 오후 \n",
    "9∼10시 전후 전남 해안에 상륙한 뒤 남부지방을 관통해 3일 오전 경북 동해안으로 빠져나갈 것으로 보인다\"고 말했습니다.\n",
    "서쪽 상층의 건조한 공기가 유입되면서 태풍은 다소 약해진 상태입니다. 오후 1시 현재 제주도와 전남, 광주에는 태풍 특보(경보)가 발효돼 있습니다.\n",
    "특보 지역은 앞으로 확대될 예정입니다.\n",
    "'''\n",
    "#출처 : 태풍 '미탁' 상륙 빨라져…오늘 밤 9∼10시 전남 해안 도착, 19-10-02, sbs 권태훈 기자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kortokens = nltk.word_tokenize(korraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['제18호', '태풍', \"'미탁\", \"'\", '', '당초', '예상보', '일찍', '한반도', '상륙할', '것', '보입니', '.', '기상청', '따르면', \"'미탁\", \"'\", '', '2일', '정오', '현재', '제주도', '서귀포', '서남서쪽', '약', '230㎞', '해상에서', '시속', '30㎞', '북북동쪽', '이동', '중입니', '.', '중간', '강도', '중형급', '태풍', \"'미탁\", \"'\", '', '중심기압', '985hPa', '(', '헥토파스칼', ')', ',', '중심', '부근', '최대', '풍속', '초속', '27ｍ', '(', '시속', '97㎞', ')', '', '.', '초속', '15ｍ', '이상', '강풍', '부', '반경', '300㎞입니', '.', '당초', \"'미탁\", \"'\", '', '이날', '밤', '12시쯤', '전남', '해안', '상륙할', '것', '예보됐지만', ',', '이동', '속도', '빨라지면서', '이날', '오후', '9∼10시께', '전남', '해안', '상륙할', '것', '예보', '보완됐습니', '.', '윤기한', '기상청', '통보관', '``', '오늘', '오후', '9∼10시', '전후', '전남', '해안', '상륙한', '뒤', '남부지방', '관통해', '3일', '오전', '경북', '동해안', '빠져나갈', '것', '보인', \"''\", '', '말했습니', '.', '서쪽', '상층', '건조한', '공기', '유입되면서', '태풍', '다소', '약해진', '상태입니', '.', '오후', '1시', '현재', '제주도', '전남', ',', '광주에', '태풍', '특보', '(', '경보', ')', '', '발효돼', '있습니', '.', '특보', '지역', '앞', '확대될', '예정입니', '.']\n"
     ]
    }
   ],
   "source": [
    "print([koreanstem(t) for t in kortokens])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
